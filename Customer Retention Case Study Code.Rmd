---
title: "Untitled"
author: "Robert Perez"
date: "4/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(SMCRM);library(dplyr);library(tidyr);library(ggplot2);library(survival);library(rpart);library(corrplot);
library(randomForestSRC);library(viridis);library(viridisLite);library(caret); library(tree); library(Metrics)
```


# Data Exploration

## Data Importing

```{r}
data("acquisitionRetention")
```

```{r}
View(acquisitionRetention)
str(acquisitionRetention)
```

## Data Cleaning

```{r}
sapply(acquisitionRetention, function(x) sum(is.na(x)))
```

```{r}
acquisitionRetention <- acquisitionRetention[,2:15]
acquisitionRetention$crossbuy <- as.factor(acquisitionRetention$crossbuy)
acquisitionRetention$industry <- as.factor(acquisitionRetention$industry)
acquisitionRetention$acquisition <- as.factor(acquisitionRetention$acquisition)
str(acquisitionRetention)
```

## Data Correlations

```{r fig.height=10}
corrplot(cor(acquisitionRetention[,c(2:7,11,13:14)]), method = "number")
```

```{r fig.height=10}
pairs(acquisitionRetention)
```

## Data Splitting

### Split for Acquisiton prediction

```{r}
set.seed(123)
idx.train <- sample(1:nrow(acquisitionRetention), size = 0.7 * nrow(acquisitionRetention))
train.df <- acquisitionRetention[idx.train,]
test.df <- acquisitionRetention[-idx.train,]
```


# Model Creation & Predictions

## Tree Model - Acquisition 

```{r}
set.seed(123)
dt.model <- rpart(acquisition ~ acq_exp + industry + revenue + employees, data = train.df) # simple DT model

rattle::fancyRpartPlot(dt.model, sub = "") # vizualize the DT
```

```{r}
predicted.acquisition <- predict(dt.model, newdata = test.df, type = "class")
View(predicted.acquisition)
```

```{r}
caret::confusionMatrix(as.factor(test.df$acquisition),as.factor(predicted.acquisition), positive='1')
```


## Logistic Model - Acquisition

```{r}
set.seed(123)
glm.model <- glm(acquisition ~ acq_exp + acq_exp_sq + industry + revenue + employees, data = train.df, family = "binomial")
summary(glm.model)
```

```{r}
car::vif(glm.model)
```


```{r}
set.seed(123)
glm.model2 <- glm(acquisition ~ acq_exp_sq + industry + revenue + employees, data = train.df, family = "binomial")
summary(glm.model2)
```

```{r}
car::vif(glm.model2)
```

```{r}
glm.preds <- predict(glm.model2, newdata = test.df, type = "response")
test.df$PredChoice = ifelse(glm.preds >= 0.5, 1,0)
test.df$PredChoice = as.factor(test.df$PredChoice)

```

```{r}
caret::confusionMatrix(as.factor(test.df$acquisition),as.factor(test.df$PredChoice), positive='1')
```



## Forest Model - Acquisition 

### theme for nice plotting
```{r}
theme_nice <- theme_classic()+
                theme(
                  axis.line.y.left = element_line(colour = "black"),
                  axis.line.y.right = element_line(colour = "black"),
                  axis.line.x.bottom = element_line(colour = "black"),
                  axis.line.x.top = element_line(colour = "black"),
                  axis.text.y = element_text(colour = "black", size = 12),
                  axis.text.x = element_text(color = "black", size = 12),
                  axis.ticks = element_line(color = "black")) +
                theme(
                  axis.ticks.length = unit(-0.25, "cm"), 
                  axis.text.x = element_text(margin=unit(c(0.5,0.5,0.5,0.5), "cm")), 
                  axis.text.y = element_text(margin=unit(c(0.5,0.5,0.5,0.5), "cm")))

```

### Manual Selection

```{r}
set.seed(123)
forest1 <- rfsrc(acquisition ~ acq_exp + acq_exp_sq + industry + revenue + employees, 
                            data = train.df, 
                            importance = TRUE, 
                            ntree = 1000)

forest1
```

```{r}
set.seed(123)
forest2 <- rfsrc(acquisition ~ acq_exp_sq + industry + revenue + employees, 
                            data = train.df, 
                            importance = TRUE, 
                            ntree = 1000)

forest2
```

```{r}
set.seed(123)
forest3 <- rfsrc(acquisition ~ acq_exp + industry + revenue + employees, 
                            data = train.df, 
                            importance = TRUE, 
                            ntree = 1000)

forest3
```

```{r}
forest3$importance
```

```{r}
forest3$importance[,1]
```



```{r}
data.frame(importance = forest3$importance[,1] +.1) %>% # add a large +ve constant
 
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "variable importance for acquisition") +
    theme_nice
```

```{r}
forest3$importance[,2]
```

```{r}
data.frame(importance = forest3$importance[,2] +.1) %>% # add a large +ve constant
 
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "variable importance for acquisition") +
    theme_nice
```

```{r}
forest3$importance[,3]
```

```{r}
data.frame(importance = forest3$importance[,3] +.1) %>% # add a large +ve constant
 
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "variable importance for acquisition") +
    theme_nice
```

### Optimized Selection

```{r}
?rfsrc

# Establish a list of possible values for hyper-parameters
mtry.values <- seq(1,4,1)
nodesize.values <- seq(1,4,1)
ntree.values <- seq(1e3,6e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of modelsfor (i in 1:nrow(hyper_grid)) {
for (i in 1:nrow(hyper_grid)) {
    # Train a Random Forest model
   set.seed(100)
   model <- rfsrc(acquisition ~ acq_exp_sq + industry + revenue + employees, 
                            data = train.df, 
                            mtry = hyper_grid$mtry[i],
                            nodesize = hyper_grid$nodesize[i],
                            ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```

```{r}
set.seed(111)
forest.hyper <- rfsrc(acquisition ~ acq_exp_sq + industry + revenue + employees, 
                            data = train.df,
                            mtry = 1,
                            nodesize = 1,
                            ntree = 1000,
                            importance = TRUE)
forest.hyper
```

```{r}
forest.hyper$importance
```

```{r}
forest.hyper$importance[,1]
```

```{r}
data.frame(importance = forest.hyper$importance[,1] +.1) %>% # add a large +ve constant
 
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "variable importance for acquisition") +
    theme_nice
```

```{r}
forest.hyper$importance[,2]
```

```{r}


data.frame(importance = forest.hyper$importance[,2] + .1) %>% # add a large +ve constant
 
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "variable importance for acquisition") +
    theme_nice
```

```{r}
forest.hyper$importance[,3]
```

```{r}
data.frame(importance = forest.hyper$importance[,3] + .1) %>% # add a large +ve constant
 
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "variable importance for acquisition") +
    theme_nice
```

```{r}
error.df <- data.frame(pred1 = predict.rfsrc(forest3,newdata = test.df)$class, 
             pred2 = predict.rfsrc(forest.hyper, newdata = test.df)$class,
             actual = test.df$acquisition) 
```


```{r}
PredsAll = predict.rfsrc(forest.hyper,newdata = acquisitionRetention)$class

Acquisition2.df <- cbind(acquisitionRetention,PredsAll)
```

```{r}
Acquired.df <- filter(Acquisition2.df, PredsAll == "1")
```

### Split for Duration prediction

```{r}
set.seed(123)
idx.train_1 <- sample(1:nrow(Acquired.df), size = 0.7 * nrow(Acquired.df))
acq_train.df <- Acquired.df[idx.train_1,]
acq_test.df <- Acquired.df[-idx.train_1,]
```


## Forest Duration Model

### Manual Selection

```{r}
set.seed(123)
forest_duration <- rfsrc(duration ~ profit + acq_exp + acq_exp_sq + ret_exp + ret_exp_sq + freq + freq_sq + crossbuy + sow + industry + revenue +employees, 
                            data = acq_train.df, 
                            importance = TRUE, 
                            ntree = 1000)

forest_duration
```

```{r}
forest_duration$importance
```

```{r}
forest_duration$importance %>% log() # log transform

data.frame(importance = forest_duration$importance + 100) %>% # add a large +ve constant
  log() %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "Log-transformed variable importance for Duration") +
    theme_nice
```

```{r}
data.frame(err.rate = forest_duration$err.rate) %>%
  na.omit() %>%
  tibble::rownames_to_column(var = "trees") %>%
  mutate(trees = as.numeric(trees)) %>%
  ggplot(aes(x = trees, y = err.rate, group = 1))+
  geom_line()+
  scale_x_continuous(breaks = seq(0,1250,100))+
  labs(x = "Number of trees", y = "OOB Error rate")+
  theme_nice
```

### Optimized Selection

```{r}

# Establish a list of possible values for hyper-parameters
mtry.values <- seq(1,12,1)
nodesize.values <- seq(1,5,1)
ntree.values <- seq(1e3,6e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of modelsfor (i in 1:nrow(hyper_grid)) {
for (i in 1:nrow(hyper_grid)) {
    # Train a Random Forest model
   set.seed(123)
   model <- rfsrc(duration ~ profit + acq_exp + acq_exp_sq + ret_exp + ret_exp_sq + freq + freq_sq + crossbuy + sow + industry + revenue +employees, 
                            data = acq_train.df, 
                            mtry = hyper_grid$mtry[i],
                            nodesize = hyper_grid$nodesize[i],
                            ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
print(hyper_grid[opt_i,])
```



```{r}
set.seed(100)

forest.hyper_duration <- rfsrc(duration ~ profit + acq_exp + acq_exp_sq + ret_exp + ret_exp_sq + freq + freq_sq + crossbuy + sow + industry + revenue + employees, 
                            data = acq_train.df,
                            mtry = 6,
                            nodesize = 1,
                            ntree = 1000,
                            importance = TRUE)
forest.hyper_duration

```

```{r}
PredsDuration = predict.rfsrc(forest.hyper_duration,newdata = acq_test.df)$predicted
DurationDF <- data.frame(acq_test.df$duration, PredsDuration)
mse(acq_test.df$duration, PredsDuration)
```

```{r}
MAE_D<-MAE(acq_test.df$duration, PredsDuration)
MAE_D
```


```{r}
forest.hyper_duration$importance
```

```{r}
forest.hyper_duration$importance %>% log() # log transform

data.frame(importance = forest.hyper_duration$importance + 100) %>% # add a large +ve constant
  log() %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.5)+
    coord_flip() +
    labs(x = "Variables", y = "Log-transformed variable importance for Duration") +
    theme_nice
```

```{r}
data.frame(err.rate = forest.hyper_duration$err.rate) %>%
  na.omit() %>%
  tibble::rownames_to_column(var = "trees") %>%
  mutate(trees = as.numeric(trees)) %>%
  ggplot(aes(x = trees, y = err.rate, group = 1))+
  geom_line()+
  scale_x_continuous(breaks = seq(0,1250,100))+
  labs(x = "Number of trees", y = "OOB Error rate")+
  theme_nice
```


# PDP Plots

## Duration: Retention Expenditure

```{r}
min(forest.hyper_duration$xvar$ret_exp)
max(forest.hyper_duration$xvar$ret_exp)
```

```{r}
ret_exp_seq = seq(0,1100,20)
```


```{r}
# extract marginal effect using partial dependence
marginal.effect <- partial(forest.hyper_duration,
                           partial.xvar = "ret_exp",
                           partial.values = ret_exp_seq)

means.exp <- marginal.effect$regrOutput$duration %>% colMeans()
```

```{r}
marginal.effect.df <-
  data.frame(pred.duration = means.exp, ret_exp_seq = ret_exp_seq)
```

```{r fig.height=10, fig.width=20}
ggplot(marginal.effect.df, aes(x = ret_exp_seq, y = pred.duration)) +
  geom_point(shape = 21, color = "purple", size = 2, stroke = 1.2)+
  geom_smooth(method = "lm", formula = y ~ poly(x,3), se = FALSE, color = "black")+ # try with other values 
  labs(x = "Average retention in $", y = "Predicted duration") +
  scale_x_continuous(breaks = seq(0,1100,20))+
  theme_nice # positive effect of ret_exp not clear as suggested by reg coefs
```


```{r }
# first check relationship between actual duration and ret_exp

ggplot(acquisitionRetention, aes(x = ret_exp, y = duration)) +
  geom_point(shape = 21, col = "purple", size = 3) +
  stat_smooth(method = "lm", se = FALSE, color = "black") +
  scale_x_continuous(breaks = seq(0,1100,100)) +
  scale_y_continuous(breaks = seq(0,2200,200)) +
  geom_rug(sides = "b", col = "red", alpha = 0.2) +
  labs(y = "Actual duration", x = "retention in $") +
  theme_nice
```


```{r fig.height=5, fig.width=10}
# repeat with smaller values of ret_exp
ret_exp_seq2 = seq(200,700,25)

marginal.effect.new <- partial(forest.hyper_duration,
                           partial.xvar = "ret_exp",
                           partial.values = ret_exp_seq2)

means.exp.new <- marginal.effect.new$regrOutput$duration %>% colMeans()

marginal.effect.df.new <-
  data.frame(pred.duration = means.exp.new, ret_exp_seq = ret_exp_seq2)

ggplot(marginal.effect.df.new, aes(x = ret_exp_seq, y = pred.duration)) +
  geom_point(shape = 21, color = "purple", size = 2, stroke = 1.2)+
  geom_path()+
  labs(x = "retention in $", y = "Predicted duration") +
  scale_x_continuous(breaks = seq(200,700,25))+
  theme_nice
```

## Duration: Crossbuy Categories

```{r fig.height=5, fig.width=10}
CrossbuyPlot <- boxplot(data=acquisitionRetention, duration ~ crossbuy)
```

```{r}
x <- c("Minimum", "25th Percentile", "Median", "75th Percentile", "Maximum")

CrossbuyStats <- data.frame(x, CrossbuyPlot$stats)
colnames(CrossbuyStats) <- c("Statistic","0","1","2","3","4","5","6","7", "8", "9", "10", "11")
```






## Duration: Retention Expenditure Squared

```{r}
min(forest.hyper_duration$xvar$ret_exp_sq)
max(forest.hyper_duration$xvar$ret_exp_sq)
```

```{r}
ret_sq_seq = seq(0,1200000,100000)

# extract marginal effect using partial dependence
marginal.effect <- partial(forest.hyper_duration,
                           partial.xvar = "ret_exp_sq",
                           partial.values = ret_sq_seq)

means.exp <- marginal.effect$regrOutput$duration %>% colMeans()

marginal.effect.df <-
  data.frame(pred.duration = means.exp, ret_sq_seq = ret_sq_seq)
```

```{r fig.height=15, fig.width=30}
ggplot(marginal.effect.df, aes(x = ret_sq_seq, y = pred.duration)) +
  geom_point(shape = 21, color = "purple", size = 2, stroke = 1.2)+
  geom_smooth(method = "lm", formula = y ~ poly(x,3), se = FALSE, color = "black")+ # try with other values 
  labs(x = "Squared Retention Expenditure", y = "Predicted duration") +
  scale_x_continuous(breaks = seq(0,1200000,100000))+
  theme_nice # positive effect of ret_exp not clear as suggested by reg coefs
```

```{r fig.width=30, fig.height=15}
# first check relationship between actual duration and ret_exp

ggplot(acquisitionRetention, aes(x = ret_exp_sq, y = duration)) +
  geom_point(shape = 21, col = "purple", size = 3) +
  stat_smooth(method = "lm", se = FALSE, color = "black") +
  scale_x_continuous(breaks = seq(0,1200000,100000)) +
  scale_y_continuous(breaks = seq(0,1800,100)) +
  geom_rug(sides = "b", col = "red", alpha = 0.2) +
  labs(y = "Actual duration", x = "Squared Retention Expenditure") +
  theme_nice
```


```{r fig.width=15, fig.height=7.5}
# repeat with smaller values of ret_exp
ret_sq_seq2 = seq(50000,500000,25000)

marginal.effect.new <- partial(forest.hyper_duration,
                           partial.xvar = "ret_exp_sq",
                           partial.values = ret_sq_seq2)

means.exp.new <- marginal.effect.new$regrOutput$duration %>% colMeans()

marginal.effect.df.new <-
  data.frame(pred.duration = means.exp.new, ret_sq_seq = ret_sq_seq2)

ggplot(marginal.effect.df.new, aes(x = ret_sq_seq, y = pred.duration)) +
  geom_point(shape = 21, color = "purple", size = 2, stroke = 1.2)+
  geom_path()+
  labs(x = "Squard Retention Expenditure", y = "Predicted duration") +
  scale_x_continuous(breaks = seq(50000,500000,25000))+
  theme_nice
```

## Duration: frequency

```{r fig.height=5, fig.width=10}
FreqPlot <- boxplot(data=acquisitionRetention, duration ~ freq)
```

```{r}
x <- c("Minimum", "25th Percentile", "Median", "75th Percentile", "Maximum")

FreqStats <- data.frame(x, FreqPlot$stats)
colnames(FreqStats) <- c("Statistic","0","1","2","3","4","5","6","7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21")
```

## Duration: frequency squared

```{r fig.height=5, fig.width=10}
FreqSqPlot <- boxplot(data=acquisitionRetention, duration ~ freq_sq)
```

```{r}
x <- c("Minimum", "25th Percentile", "Median", "75th Percentile", "Maximum")

FreqSqStats <- data.frame(x, FreqSqPlot$stats)
colnames(FreqSqStats) <- c("Statistic","0","1","4","9","16","25","36","49", "64", "81", "100", "121", "144", "169", "196", "225", "256", "289", "324", "361", "400", "441")
```

# Minimal Depth

```{r}
mindepth <- max.subtree(forest.hyper_duration, sub.order = TRUE)

print(round(mindepth$order, 3)[,1])
```


```{r}
data.frame(md = round(mindepth$order, 3)[,1]) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,desc(md)), y = md)) +
    geom_bar(stat = "identity", fill = "orange", color = "black", width = 0.2)+
    coord_flip() +
     labs(x = "Variables", y = "Minimal Depth")+
     theme_nice
```

```{r fig.height=5, fig.width=10}
as.matrix(mindepth$sub.order) %>%
  reshape2::melt() %>%
  data.frame() %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
    scale_x_discrete(position = "top") +
    geom_tile(color = "white") +
    viridis::scale_fill_viridis("Relative min. depth") +
    labs(x = "", y = "") +
    theme_bw()
```


